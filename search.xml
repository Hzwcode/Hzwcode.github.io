<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[music test]]></title>
      <url>%2F2017%2F02%2F26%2Fmusic-test%2F</url>
      <content type="text"><![CDATA[new APlayer({ element: document.getElementById("aplayer0"), narrow: false, autoplay: false, showlrc: 0, music: { title: "童话镇", author: "陈一发儿", url: "http://mp3.haoduoge.com/s/2016-12-24/1482568978.mp3", pic: "http://p3.music.126.net/tfa811GLreJI_S0h9epqRA==/3394192426154346.jpg?param=130y130", } });]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[[RNN] Simple LSTM代码实现 & BPTT理论推导]]></title>
      <url>%2F2017%2F02%2F24%2FBackpropagation-through-time-BPTT%2F</url>
      <content type="text"><![CDATA[参考：Nico’s Blog - Simple LSTM Github代码：https://github.com/Hzwcode/lstm 前面我们介绍过CNN中普通的BP反向传播算法的推导，但是在RNN（比如LSTM）中，反向传播被称作BPTT（Back Propagation Through Time），它是和时间序列有关的。 A few weeks ago I released some code on Github to help people understand how LSTM’s work at the implementation level. The forward pass is well explained elsewhere and is straightforward to understand, but I derived the backprop equations myself and the backprop code came without any explanation whatsoever. The goal of this post is to explain the so called backpropagation through time in the context of LSTM’s. If you feel like anything is confusing, please post a comment below or submit an issue on Github. Note: this post assumes you understand the forward pass of an LSTM network, as this part is relatively simple. Please read this great intro paper if you are not familiar with this, as it contains a very nice intro to LSTM’s. I follow the same notation as this paper so I recommend reading having the tutorial open in a separate browser tab for easy reference while reading this post. Introduction (Simple LSTM) The forward pass of an LSTM node is defined as follows: (注：这里最后一个式子h(t)的计算，普遍认为s(t)前面还有一个tanh激活，然后再乘以o(t)，不过 peephole LSTM paper中建议此处激活函数采用 f(x) = x，所以这里就没有用tanh（下同），可以参见Wiki - Long_short-term_memory上面所说的) By concatenating the x(t) and h(t-1) vectors as follows: we can rewrite parts of the above as follows: Suppose we have a loss l(t) that we wish to minimize at every time step t that depends on the hidden layer h and the label y at the current time via a loss function f: where f can be any differentiable loss function, such as the Euclidean loss: Our ultimate goal in this case is to use gradient descent to minimize the loss L over an entire sequence of length T： Let’s work through the algebra of computing the loss gradient: where w is a scalar parameter of the model (for example it may be an entry in the matrix W_gx). Since the loss l(t) = f(h(t),y(t)) only depends on the values of the hidden layer h(t) and the label y(t), we have by the chain rule: where h_i(t) is the scalar corresponding to the i’th memory cell’s hidden output and M is the total number of memory cells. Since the network propagates information forwards in time, changing h_i(t) will have no effect on the loss prior to time t, which allows us to write: For notational convenience we introduce the variable L(t) that represents the cumulative loss from step tonwards: such that L(1) is the loss for the entire sequence. This allows us to rewrite the above equation as: With this in mind, we can rewrite our gradient calculation as: Make sure you understand this last equation. The computation of dh_i(t) / dw follows directly follows from the forward propagation equations presented earlier. We now show how to compute dL(t) / dh_i(t) which is where the so called backpropagation through time comes into play. Backpropagation through time (BPTT) This variable L(t) allows us to express the following recursion: Hence, given activation h(t) of an LSTM node at time t, we have that: Now, we know where the first term on the right hand side dl(t) / dh(t) comes from: it’s simply the elementwise derivative of the loss l(t) with respect to the activations h(t) at time t. The second term dL(t+1) / dh(t) is where the recurrent nature of LSTM’s shows up. It shows that the we need the next node’s derivative information in order to compute the current current node’s derivative information. Since we will ultimately need to compute dL(t) / dh(t) for all t = 1, 2, ... , T, we start by computing and work our way backwards through the network. Hence the term backpropagation through time. With these intuitions in place, we jump into the code. Code (Talk is cheap, Show me the code) We now present the code that performs the backprop pass through a single node at time 1 &lt;= t &lt;= T. The code takes as input: And computes: whose values will need to be propagated backwards in time. The code also adds derivatives to: since recall that we must sum the derivatives from each time step: Also, note that we use: where we recall that X_c(t) = [x(t), h(t-1)]. Without any further due, the code: 1234567891011121314151617181920212223242526272829303132333435def top_diff_is(self, top_diff_h, top_diff_s): # notice that top_diff_s is carried along the constant error carousel ds = self.state.o * top_diff_h + top_diff_s do = self.state.s * top_diff_h di = self.state.g * ds dg = self.state.i * ds df = self.s_prev * ds # diffs w.r.t. vector inside sigma / tanh function di_input = (1. - self.state.i) * self.state.i * di df_input = (1. - self.state.f) * self.state.f * df do_input = (1. - self.state.o) * self.state.o * do dg_input = (1. - self.state.g ** 2) * dg # diffs w.r.t. inputs self.param.wi_diff += np.outer(di_input, self.xc) self.param.wf_diff += np.outer(df_input, self.xc) self.param.wo_diff += np.outer(do_input, self.xc) self.param.wg_diff += np.outer(dg_input, self.xc) self.param.bi_diff += di_input self.param.bf_diff += df_input self.param.bo_diff += do_input self.param.bg_diff += dg_input # compute bottom diff dxc = np.zeros_like(self.xc) dxc += np.dot(self.param.wi.T, di_input) dxc += np.dot(self.param.wf.T, df_input) dxc += np.dot(self.param.wo.T, do_input) dxc += np.dot(self.param.wg.T, dg_input) # save bottom diffs self.state.bottom_diff_s = ds * self.state.f self.state.bottom_diff_x = dxc[:self.param.x_dim] self.state.bottom_diff_h = dxc[self.param.x_dim:] Details The forward propagation equations show that modifying s(t) affects the loss L(t) by directly changing the values of h(t) as well as h(t+1). However, modifying s(t) affects L(t+1) only by modifying h(t+1). Therefore, by the chain rule: Since the forward propagation equations state: we get that: Putting all this together we have: 1ds = self.state.o * top_diff_h + top_diff_s The rest of the equations should be straightforward to derive, please let me know if anything is unclear. Test LSTM Network 此 代码 其是通过自己实现 lstm 网络来逼近一个序列，y_list = [-0.5, 0.2, 0.1, -0.5]，测试结果如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687cur iter: 0y_pred[0] : 0.041349y_pred[1] : 0.069304y_pred[2] : 0.116993y_pred[3] : 0.165624loss: 0.753483886253cur iter: 1y_pred[0] : -0.223297y_pred[1] : -0.323066y_pred[2] : -0.394514y_pred[3] : -0.433984loss: 0.599065083953cur iter: 2y_pred[0] : -0.140715y_pred[1] : -0.181836y_pred[2] : -0.219436y_pred[3] : -0.238904loss: 0.445095565699cur iter: 3y_pred[0] : -0.138010y_pred[1] : -0.166091y_pred[2] : -0.203394y_pred[3] : -0.233627loss: 0.428061605701cur iter: 4y_pred[0] : -0.139986y_pred[1] : -0.157368y_pred[2] : -0.195655y_pred[3] : -0.237612loss: 0.413581711096cur iter: 5y_pred[0] : -0.144410y_pred[1] : -0.151859y_pred[2] : -0.191676y_pred[3] : -0.246137loss: 0.399770442382cur iter: 6y_pred[0] : -0.150306y_pred[1] : -0.147921y_pred[2] : -0.189501y_pred[3] : -0.257119loss: 0.386136380384cur iter: 7y_pred[0] : -0.157119y_pred[1] : -0.144659y_pred[2] : -0.188067y_pred[3] : -0.269322loss: 0.372552465753cur iter: 8y_pred[0] : -0.164490y_pred[1] : -0.141537y_pred[2] : -0.186737y_pred[3] : -0.281914loss: 0.358993892096cur iter: 9y_pred[0] : -0.172187y_pred[1] : -0.138216y_pred[2] : -0.185125y_pred[3] : -0.294326loss: 0.345449256686cur iter: 10y_pred[0] : -0.180071y_pred[1] : -0.134484y_pred[2] : -0.183013y_pred[3] : -0.306198loss: 0.331888922037……cur iter: 97y_pred[0] : -0.500351y_pred[1] : 0.201185y_pred[2] : 0.099026y_pred[3] : -0.499154loss: 3.1926009167e-06cur iter: 98y_pred[0] : -0.500342y_pred[1] : 0.201122y_pred[2] : 0.099075y_pred[3] : -0.499190loss: 2.88684626031e-06cur iter: 99y_pred[0] : -0.500331y_pred[1] : 0.201063y_pred[2] : 0.099122y_pred[3] : -0.499226loss: 2.61076360677e-06 可以看出迭代100轮，最后Loss在不断收敛，并且逐渐逼近了预期序列：y_list = [-0.5, 0.2, 0.1, -0.5]。 Reference 深度学习 — 反向传播(BP)理论推导 (zhwhong) Nico’s Blog：Simple LSTM Github仓库：https://github.com/Hzwcode/lstm RECURRENT NEURAL NETWORKS TUTORIAL, PART 3 – BACKPROPAGATION THROUGH TIME AND VANISHING GRADIENTS [福利] 深入理解 RNNs &amp; LSTM 网络学习资料 关于简书中如何编辑Latex数学公式 (喜欢的可以点一下红心，转载请注明出处，谢谢！)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[深度学习 — 反向传播(BP)理论推导]]></title>
      <url>%2F2017%2F02%2F24%2FBackpropagation-principle%2F</url>
      <content type="text"><![CDATA[关于简书中如何编辑Latex数学公式 [RNN] Simple LSTM代码实现 &amp; BPTT理论推导 【知识预备】： UFLDL教程 - 反向传导算法 首先我们不讲数学，先上图解，看完图不懂再看后面： “BP” Math Principle======================================================================Example：下面看一个简单的三层神经网络模型，一层输入层，一层隐藏层，一层输出层。 注：定义输入分别为x1, x2（对应图中的i1，i2），期望输出为y1，y2，假设logistic函数采用sigmoid函数: 易知： 下面开始正式分析(纯手打！！！)。 ====================================================================== 前向传播首先分析神经元h1： 同理可得神经元h2： 对输出层神经元重复这个过程，使用隐藏层神经元的输出作为输入。这样就能给出o1，o2的输入输出： 现在开始统计所有误差，如下： ====================================================================== 反向传播【输出层】对于w5，想知道其改变对总误差有多少影响，于是求Jtotal对w5的偏导数，如下： 分别求每一项： 于是有Jtotal对w5的偏导数： 据此更新权重w5，有： 同理可以更新参数w6，w7，w8。在有新权重导入隐藏层神经元（即，当继续下面的反向传播算法时，使用原始权重，而不是更新的权重）之后，执行神经网络中的实际更新。 【隐藏层】 对于w1，想知道其改变对总误差有多少影响，于是求Jtotal对w1的偏导数，如下： 分别求每一项： 于是有Jtotal对w1的偏导数： 据此更新w1，有： 同理可以更新参数w2，w3，w4。 ====================================================================== 应用实例假设对于上述简单三层网络模型，按如下方式初始化权重和偏置： 根据上述推导的公式：由 得到：input(h1) = 0.15 * 0.05 + 0.20 * 0.10 + 0.35 = 0.3775output(h1) = f(input(h1)) = 1 / (1 + e^(-input(h1))) = 1 / (1 + e^-0.3775) = 0.593269992 同样得到：input(h2) = 0.25 * 0.05 + 0.30 * 0.10 + 0.35 = 0.3925output(h2) = f(input(h2)) = 1 / (1 + e^(-input(h2))) = 1 / (1 + e^-0.3925) = 0.596884378 对输出层神经元重复这个过程，使用隐藏层神经元的输出作为输入。这样就能给出o1的输出：input(o1) = w5 * output(h1) + w6 * (output(h2)) + b2 = 0.40 * 0.593269992 + 0.45 * 0.596884378 + 0.60 = 1.105905967output(o1) = f(input(o1)) = 1 / (1 + e^-1.105905967) = 0.75136507 同理output(o2) = 0.772928465 开始统计所有误差，求代价函数：Jo1 = 1/2 * (0.75136507 - 0.01)^2 = 0.298371109Jo2 = 1/2 * (0.772928465 - 0.99)^2 = 0.023560026 综合所述，可以得到总误差为：Jtotal = Jo1 + Jo2 = 0.321931135 然后反向传播，根据公式 求出 Jtotal对w5的偏导数为:a = (0.75136507 - 0.01)*0.75136507*(1-0.75136507)*0.593269992 = 0.082167041 为了减少误差，然后从当前的权重减去这个值（可选择乘以一个学习率，比如设置为0.5），得：w5+ = w5 - eta * a = 0.40 - 0.5 * 0.082167041 = 0.35891648 同理可以求出：w6+ = 0.408666186w7+ = 0.511301270w8+ = 0.561370121 对于隐藏层，更新w1，求Jtotal对w1的偏导数： 偏导数为：b = (tmp1 + tmp2) * tmp3 tmp1 = (0.75136507 - 0.01) * [0.75136507 * (1 - 0.75136507)] * 0.40 = 0.74136507 * 0.186815602 * 0.40 = 0.055399425tmp2 = -0.019049119tmp3 = 0.593269992 * (1 - 0.593269992) * 0.05 = 0.012065035 于是b = 0.000438568 更新权重w1为：w1+ = w1 - eta * b = 0.15 - 0.5 * 0.000438568 = 0.149780716 同样可以求得：w2+ = 0.19956143w3+ = 0.24975114w4+ = 0.29950229 最后，更新了所有的权重！ 当最初前馈传播时输入为0.05和0.1，网络上的误差是0.298371109。 在第一轮反向传播之后，总误差现在下降到0.291027924。 它可能看起来不太多，但是在重复此过程10,000次之后。例如，错误倾斜到0.000035085。在这一点上，当前馈输入为0.05和0.1时，两个输出神经元产生0.015912196（相对于目标为0.01）和0.984065734（相对于目标为0.99），已经很接近了O(∩_∩)O~~ Reference https://zhuanlan.zhihu.com/p/23270674 Principles of training multi-layer neural network using backpropagation [RNN] Simple LSTM代码实现 &amp; BPTT理论推导 简书中如何编辑Latex数学公式 (转载请注明出处： 深度学习 — 反向传播(BP)理论推导(zhwhong))]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[[Detection] CNN 之 "物体检测" 篇]]></title>
      <url>%2F2017%2F02%2F24%2FDetection-CNN%2F</url>
      <content type="text"><![CDATA[Index RCNN Fast RCNN Faster RCNN R-FCN YOLO SSD NMS xywh VS xyxy RCNNRich feature hierarchies for accurate object detection and semantic segmentation 早期，使用窗口扫描进行物体识别，计算量大。 RCNN去掉窗口扫描，用聚类方式，对图像进行分割分组，得到多个侯选框的层次组。 原始图片通过Selective Search提取候选框，约有2k个 侯选框缩放成固定大小 经过CNN 经两个全连接后，分类 拓展阅读：基于R-CNN的物体检测-CVPR 2014 Fast RCNNFast R-CNN RCNN中有CNN重复计算，Fast RCNN则去掉重复计算，并微调选框位置。 整图经过CNN，得到特征图 提取域候选框 把候选框投影到特征图上，Pooling采样成固定大小 经两个全连接后，分类与微调选框位置 Faster RCNNFaster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks 提取候选框运行在CPU上，耗时2s，效率低下。Faster RCNN使用CNN来预测候选框。 整图经过CNN，得到特征图 经过核为 3×3×256 的卷积，每个点上预测k个anchor box是否是物体，并微调anchor box的位置 提取出物体框后，采用Fast RCNN同样的方式，进行分类 选框与分类共用一个CNN网络 anchor box的设置应比较好的覆盖到不同大小区域，如下图: 一张1000×600的图片，大概可以得到20k个anchor box(60×40×9)。 R-FCNR-FCN: Object Detection via Region-based Fully Convolutional Networks 论文翻译详见：[译] 基于R-FCN的物体检测 (zhwhong) RCNN系列(RCNN、Fast RCNN、Faster RCNN)中，网络由两个子CNN构成。在图片分类中，只需一个CNN，效率非常高。所以物体检测是不是也可以只用一个CNN？ 图片分类需要兼容形变，而物体检测需要利用形变，如何平衡？ R-FCN利用在CNN的最后进行位置相关的特征pooling来解决以上两个问题。 经普通CNN后，做有 k^2(C+1) 个 channel 的卷积，生成位置相关的特征(position-sensitive score maps)。 C 表示分类数，加 1 表示背景，k 表示后续要pooling 的大小，所以生成 k^2 倍的channel，以应对后面的空间pooling。 普通CNN后，还有一个RPN(Region Proposal Network)，生成候选框。 假设一个候选框大小为 w×h，将它投影在位置相关的特征上，并采用average-pooling的方式生成一个 k×k×k^2(C+1) 的块(与Fast RCNN一样)，再采用空间相关的pooling(k×k平面上每一个点取channel上对应的部分数据)，生成 k×k×(C+1)的块，最后再做average-pooling生成 C+1 的块，最后做softmax生成分类概率。 类似的，RPN也可以采用空间pooling的结构，生成一个channel为 4k^2的特征层。 空间pooling的具体操作可以参考下面。 训练与SSD相似，训练时拿来做lost计算的点取一个常数，如128。 除去正点，剩下的所有使用概率最高的负点。 YOLOYou Only Look Once: Unified, Real-Time Object Detection Faster RCNN需要对20k个anchor box进行判断是否是物体，然后再进行物体识别，分成了两步。 YOLO则把物体框的选择与识别进行了结合，一步输出，即变成”You Only Look Once”。 把原始图片缩放成448×448大小 运行单个CNN 计算物体中心是否落入单元格、物体的位置、物体的类别 模型如下: 把缩放成统一大小的图片分割成S×S的单元格 每个单元格输出B个矩形框(冗余设计)，包含框的位置信息(x, y, w, h)与物体的Confidence 每个单元格再输出C个类别的条件概率P(Class∣Object) 最终输出层应有S×S×(B∗5+C)个单元 x, y 是每个单元格的相对位置 w, h 是整图的相对大小 Conficence定义如下: 在原论文中，S = 7，B = 2，C = 20，所以输出的单元数为7×7×30。 代价函数： 其中 λ_coord=5，λ_noobj=0.5。一般，w与 h 不是在 [0,1]上的均匀分布，偏小，所以开方。 注: 开方的解释是我自己的估计，可能不对。 SSDSSD: Single Shot MultiBox Detector YOLO在 7×7 的框架下识别物体，遇到大量小物体时，难以处理。SSD则在不同层级的feature map下进行识别，能够覆盖更多范围。 假设在 m 层 feature map 上进行识别，则第 k 层的基本比例为 比如 s_min=0.2，s_max=0.95，表示整张图片识别物体所占比最小 0.2，最大 0.95。 在基本比例上，再取多个长宽比，令 a={1, 2, 3, 1/2, 1/3}，长宽分别为 Match策略上，取ground truth与以上生成的格子重叠率大于0.5的。 SSD vs YOLO 位置采用Smooth L1 Regression，分类采用Softmax。代价函数为： x 表示类别输出，c 表示目标分类，l 表示位置输出，g 表示目标位置, α是比例常数，可取1。训练过程中负点远多于正点，所以只取负点中，概率最大的几个，数量与正点成 3:1 。 NMS以上方法，同一物体可能有多个预测值。可用NMS(Non-maximum suppression，非极大值抑制)来去重。 如上图所示，一共有6个识别为人的框，每一个框有一个置信率。现在需要消除多余的: 按置信率排序: 0.95, 0.9, 0.9, 0.8, 0.7, 0.7 取最大0.95的框为一个物体框 剩余5个框中，去掉与0.95框重叠率大于0.6(可以另行设置)，则保留0.9, 0.8, 0.7三个框 重复上面的步骤，直到没有框了，0.9为一个框 选出来的为: 0.95, 0.9 两个矩形的重叠率计算方式如下: xywh VS xyxy系列论文中，位置都用 (x,y,w,h)来表示，没有用左上角、右下角 (x,y,x,y) 来表示。初衷是当 (w,h)正确时，(x,y) 一点错，会导致整个框就不准了。在初步的实际实验中，(x,y,x,y) 效果要差一些。 背后的逻辑，物体位置用 (x,y,w,h) 来学习比较容易。(x,y) 只需要位置相关的加权就能计算出来；(w,h) 就更简单了，直接特征值相加即可。 原文链接：Detection 参考：[译] 基于R-FCN的物体检测 (zhwhong) (转载请注明出处：[Detection] CNN 之 “物体检测” 篇 (zhwhong))]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[[斯坦福CS231n课程整理] Convolutional Neural Networks for Visual Recognition(附翻译，作业)]]></title>
      <url>%2F2017%2F02%2F24%2FConvolutional-Neural-Networks-for-Visual-Recognition-CS231n%2F</url>
      <content type="text"><![CDATA[CS231n课程：面向视觉识别的卷积神经网络 课程官网：CS231n: Convolutional Neural Networks for Visual Recognition Github：https://github.com/cs231n/cs231n.github.io | http://cs231n.github.io/ 教学安排及大纲：Schedule and Syllabus 课程视频：Youtube上查看Andrej Karpathy创建的播放列表，或者网易云课堂 课程pdf及视频下载：百度网盘下载，密码是4efx 授课 (Stanford Vision Lab) Fei-Fei Li (Associate Professor, Stanford University) Andrej Karpathy | Github | Blog | Twitter Justin Johnson | Github 课程原文 &amp; 作业 &amp; 中文翻译笔记 知乎专栏：智能单元 作者：杜客 (在此对作者表示特别感谢！) 贺完结！CS231n官方笔记授权翻译总集篇发布 获得授权翻译斯坦福CS231n课程笔记系列 CS231n课程笔记翻译：Python Numpy教程 | 课程原文 CS231n课程笔记翻译：图像分类笔记（上） | 课程原文 CS231n课程笔记翻译：图像分类笔记（下） CS231n课程笔记翻译：线性分类笔记（上） | 课程原文 CS231n课程笔记翻译：线性分类笔记（中） CS231n课程笔记翻译：线性分类笔记（下） 知友智靖远关于CS231n课程字幕翻译的倡议 CS231n课程笔记翻译：最优化笔记（上） | 课程原文 CS231n课程笔记翻译：最优化笔记（下） CS231n课程笔记翻译：反向传播笔记 | 课程原文 斯坦福CS231n课程作业 # 1 简介 | 课程原文 CS231n课程笔记翻译：神经网络笔记 1（上） | 课程原文 CS231n课程笔记翻译：神经网络笔记 1（下） CS231n课程笔记翻译：神经网络笔记 2 | 课程原文 CS231n课程笔记翻译：神经网络笔记 3（上） | 课程原文 CS231n课程笔记翻译：神经网络笔记 3（下） 斯坦福CS231n课程作业 # 2 简介 | 课程原文 CS231n课程笔记翻译：卷积神经网络笔记 | 课程原文 斯坦福CS231n课程作业 # 3 简介 | 课程原文 Andrej Karpathy的回信和Quora活动邀请 知行合一码作业，深度学习真入门 【附录 - Assignment】： [简书] CS231n (winter 2016) : Assignment1 [简书] CS231n (winter 2016) : Assignment2 [简书] CS231n (winter 2016) : Assignment3（更新中） [Github] CS231n作业 参考1 | 参考2 …… (再次感谢智能单元-知乎专栏，以及知乎作者@杜客和相关朋友@ShiqingFan，@猴子，@堃堃，@李艺颖等为CS231n课程翻译工作做出的贡献，辛苦了！) 其他课程整理： [斯坦福CS224d课程整理] Natural Language Processing with Deep Learning @ zhwhong [斯坦福CS229课程整理] Machine Learning Autumn 2016 @ zhwhong [coursera 机器学习课程] Machine Learning by Andrew Ng @ zhwhong]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[[Linux] Ubuntu下超好看扁平主题 : Flatabulous]]></title>
      <url>%2F2017%2F02%2F24%2FLinux-Ubuntu_Flatabulous%2F</url>
      <content type="text"><![CDATA[使用ubuntu的小伙伴们，不知道你们对ubuntu自带主题有什么看法，反正我个人不太喜欢，个人比较喜欢扁平化的风格。下面给大家推荐一个我长期使用的扁平化风格的主题－Flatabulous 。先看一下我的桌面(个人比较偏向单色调，不要在意这些细节啦)： 那么Flatabulous到底是什么呢？ “This is a Flat theme for Ubuntu and other debian based Linux Systems. This is based on the Ultra-Flat theme. Special thanks to @steftrikia and Satyajit Sahoo for the original work.”哈哈，不卖关子了，它其实就是一个超级好看的扁平化Ubuntu主题。 下面就开始说说怎么安装它吧~ [ 安装 ]Step 1 安装 Unity Tweak Tool要安装这个主题，首先要安装Unity Tweak Tool或者Ubuntu Tweak Tool。安装Unity Tweak Tool可以很简单地执行如下命令：1$ sudo apt-get install unity-tweak-tool 安装Ubuntu Tweak Tool可以使用如下命令：123$ sudo add-apt-repository ppa:tualatrix/ppa $ sudo apt-get update$ sudo apt-get install ubuntu-tweak 或者跑到它们的网站下载.deb文件(推荐)，打开Ubuntu软件中心安装或者使用命令dpkg -i(推荐)安装。 注：If you are on Ubuntu 16.04 or higher, run the commands below to install Ubuntu Tweak: 1234$ wget -q -O - http://archive.getdeb.net/getdeb-archive.key | sudo apt-key add -$ sudo sh -c &apos;echo &quot;deb http://archive.getdeb.net/ubuntu xenial-getdeb apps&quot; &gt;&gt; /etc/apt/sources.list.d/getdeb.list&apos;$ sudo apt-get update$ sudo apt-get install ubuntu-tweak 安装完毕后，我们可以就搜到Ubuntu Tweak这款软件了，如下图： Step 2 安装Flatabulous主题方式1：Using the .deb file for Debian, Ubuntu and derivatives (Recommended)下载.deb文件，点击这里，下载后，打开Ubuntu软件中心或者使用命令dpkg -i（推荐）安装。 方式2：Using the noobslab PPA123$ sudo add-apt-repository ppa:noobslab/themes$ sudo apt-get update$ sudo apt-get install flatabulous-theme 方式3：下载Flatabulous源码下载主题源码，点击这里，或者使用git克隆下来，Github仓库地址： https://github.com/anmoljagetia/Flatabulous如果下载的是zip文件，先将其解压，然后移动到/usr/share/themes/下。如果是git clone下来的，直接执行下如下命令： 1$ sudo mv Flatabulous /usr/share/themes/ Step 3 Tweak配置我们打开Ubuntu Tweak，选择调整-&gt;主题，如下： 然后，配置GTK主题和窗口主题，选择Flatabulous，如下： 你们可以模仿我的配置，不过此时还有一个问题，就是你发现图标主题没有Ultra-Flat选项，这个icon需要额外下载，原生的Tweak里面并没有。对于图标，我使用的是ultra-flat-icons主题。有蓝色（推荐），橙色和薄荷绿颜色可用。要安装它，你可以运行下面的命令：123$ sudo add-apt-repository ppa:noobslab/icons$ sudo apt-get update$ sudo apt-get install ultra-flat-icons 或者你也可以运行sudo apt-get install ultra-flat-icons-orange或者 sudo apt-get install ultra-flat-icons-green。根据你自己喜欢的颜色选择，我推荐的是扁平图标，但是你也可以看看Numix和Flattr。 图标安装好后，再打开Ubuntu Tweak，选择 调整-&gt;主题，选择图标主题为Ultra-Flat。 安装完以后，只需要在theme进行相应的配置，然后换一个自己喜欢的桌面壁纸，我们就能看到超级好看的ubuntu啦。如果不行，重启计算机，应该就可以了。重启之后你的计算机看起来差不多是这样的： [ 部分效果图截图 ]文件管理 Theme with Sublime Text 3 and JavaScript Code 系统设置 Posters Terminal [ Reference ] Flatabulous：超级好看的Ubuntu 扁平主题 Github -&gt; Flatabulous (转载请注明原作者及出处, 谢谢！)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Machine Learning Materials]]></title>
      <url>%2F2017%2F02%2F23%2FMachine-Learning-Materials%2F</url>
      <content type="text"><![CDATA[Awesome系列 Awesome Machine Learning Awesome Deep Learning Awesome TensorFlow Awesome TensorFlow Implementations Awesome Torch Awesome Computer Vision Awesome Deep Vision Awesome RNN Awesome NLP Awesome AI Awesome Deep Learning Papers Awesome 2vec Deep Learning [Book] Neural Networks and Deep Learning 中文翻译(不完整): 神经网络与深度学习 第五章中文翻译: [译] 第五章 深度神经网络为何很难训练 [Book] Deep Learning - MIT Press [Book] Pattern Recognition and Machine Learning (Bishop) | 豆瓣 | PRML &amp; DL笔记 | GitBook [Course] Deep Learning - Udacity [Course] Machine Learning by Andrew Ng - Coursera | 课程资料整理 @ zhwhong [Course] Convolutional Neural Networks for Visual Recognition(CS231n) | 课程资料整理 @ zhwhong [Course] Deep Learning for Natural Language Processing(CS224d) | 课程资料整理 @ zhwhong [View] Top Deep Learning Projects on Github [View] Deep Learning for NLP resources [View] 资源 | 深度学习资料大全：从基础到各种网络模型 [View] Paper | DL相关论文中文翻译 [View] 深度学习新星：GAN的基本原理、应用和走向 [View] 推荐 | 九本不容错过的深度学习和神经网络书籍 [View] Github好东西传送门 –&gt; 深度学习入门与综述资料 Frameworks TensorFlow (by google) MXNet Torch (by Facebook) [Caffe (by UC Berkley)(http://caffe.berkeleyvision.org/) [Deeplearning4j(http://deeplearning4j.org) Brainstorm Theano、Chainer、Marvin、Neon、ConvNetJS TensorFlow 官方文档 TensorFlow Tutorial TensorFlow 官方文档中文版 TensorFlow Whitepaper [译] TensorFlow白皮书 [API] API Document 入门教程 [教程] Learning TensorFlow TensorFlow-Tutorials @ github (推荐) Awesome-TensorFlow (推荐) TensorFlow-Examples @ github tensorflow_tutorials @ github 分布式教程 Distributed TensorFlow官方文档 distributed-tensorflow-example @ github (推荐) DistributedTensorFlowSample @ github Parameter Server Paper (Model) CNN Nets LeNet AlexNet OverFeat NIN GoogLeNet Inception-V1 Inception-V2 Inception-V3 Inception-V4 Inception-ResNet-v2 ResNet 50 ResNet 101 ResNet 152 VGG 16 VGG 19 (注：图片来自 Github : TensorFlow-Slim image classification library) 额外参考： [ILSVRC] 基于OverFeat的图像分类、定位、检测 [卷积神经网络-进化史] 从LeNet到AlexNet [透析] 卷积神经网络CNN究竟是怎样一步一步工作的？ GoogLenet中，1X1卷积核到底有什么作用呢？ 深度学习 — 反向传播(BP)理论推导 无痛的机器学习第一季目录 - 知乎 Object Detection R-CNN Fast R-CNN Faster R-CNN FCN R-FCN YOLO SSD 额外参考： [Detection] CNN 之 “物体检测” 篇 计算机视觉中 RNN 应用于目标检测 Machine Learning 硬件投入调研 RNN &amp; LSTM [福利] 深入理解 RNNs &amp; LSTM 网络学习资料 @ zhwhong [RNN] Simple LSTM代码实现 &amp; BPTT理论推导 @ zhwhong 计算机视觉中 RNN 应用于目标检测 @ zhwhong [推荐] Understanding LSTM Networks @ colah | 理解LSTM网络[简书] @ Not_GOD The Unreasonable Effectiveness of Recurrent Neural Networks @ Andrej Karpathy LSTM Networks for Sentiment Analysis (theano官网LSTM教程+代码) Recurrent Neural Networks Tutorial @ WILDML Anyone Can Learn To Code an LSTM-RNN in Python (Part 1: RNN) @ iamtrask Stanford 机器学习课程整理 [coursera 机器学习课程] Machine Learning by Andrew Ng @ zhwhong [斯坦福CS231n课程整理] Convolutional Neural Networks for Visual Recognition（附翻译，下载） @ zhwhong [斯坦福CS224d课程整理] Natural Language Processing with Deep Learning @ zhwhong [斯坦福CS229课程整理] Machine Learning Autumn 2016 @ zhwhong ( 个人整理，未经允许禁止转载，授权转载请注明作者出处：Machine Learning 学习资料 (zhwhong) ，谢谢！)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Welcome to Hexo]]></title>
      <url>%2F2017%2F02%2F23%2Fhello-world%2F</url>
      <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
    </entry>

    
  
  
</search>
